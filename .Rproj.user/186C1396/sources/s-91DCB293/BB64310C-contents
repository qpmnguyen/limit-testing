---
title: "Election prediction using Elo"
description: |
  A fun project to predict the 2020 presidential election using weekly average polling data and Elo models
author:
  - name: Quang Nguyen
date: 01-10-2021
categories:
  - fun
  - elo modelling
  - prediction 
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, layout = "l-body-outset")
```

## Overview

This post is a re-adaptation and R-implementation of my previous post on a fun modeling project using Elo to predict the latest 2020 presidential elections. The previous implementation was done in Julia and can be found in this interactive Pluto.jl [document](https://mybinder.org/v2/gh/fonsp/pluto-on-binder/master?urlpath=pluto/open?url=https%253A%252F%252Fgithub.com%252Fqpmnguyen%252Felo_presidente%252Fblob%252Fmaster%252Fanalysis.jl%253Fraw%253Dtrue). You can find the source code for the Julia implementation [here](https://github.com/qpmnguyen/elo_presidente). For this exercise, first let's load our libraries:

```{r lib_loading, message=FALSE, warning=FALSE, echo=TRUE}
library(tidyverse)
library(lubridate)
```

## What is an Elo model?

The elo rating system is a method developed by [Arpad Elo](https://en.wikipedia.org/wiki/Arpad_Elo) in order to rank players by ability in a zero sum game. Elo has been used in various contexts, most famously the way to rank chess players through the UCSF and FIDE systems. Elo has been used in modern contexts as well, from Tinder to World of Warcraft. A really nice attribute about Elo is that a difference in scores can be translated to a probability, through the formula:

$$E_A = \frac{1}{1 + 10^{R_A - R_B}}$$ where $E_A$ is the expected score of player $A$ with rank $R_A$ playing against player $B$ of rank $R_B$. This is equivalent to applying the logistic function to a rescaled version of the difference in rankings\
$$logistic\left(\frac{\log(10)}{400} (R_A - R_B)\right)$$

The above is the most common formulation of Elo. Through the logistic function, the expected values for players $A$ and $B$ are bounded between 0 and 1 and hence can act as probabilities.

In an elo model, after each match, the rankings are updated as:\
$$R_A* = R_A + K \cdot (outcome - E_A)$$

where $K$ is the K-factor controlling the relative gains and losses of elo points. As such, let's define a couple of functions reflecting the ideas above:

```{r functions, echo=TRUE}
# Calculate win probabilities from two rankings  

win_prob <- function(r1, r2){
  x1 <- log(10)/400 * (r1 - r2)
  p1 <- plogis(x1)
  p2 <- 1 - p1
  return(list(p1 = p1 , p2 = p2))
}

# Back transform  
back_transformation <- function(prob){
  qlogis(prob) * 400 * (1/log(10))
}
```

## The US presidential election as a pseudo-sports contest  

The US presidential election is a surprisingly appropriate context to use elo. In this election, two candidates compete for the "title" of the President of the United States. Polling data is collected regularly, which can act as "matches" where the two candidates can test their "mettle" before the final election day. Furthermore, the structure of the election, a winner-take-all Electoral College system, makes it even closer to being a sports match.

In this instance, elo system is applied to model the probability of winning an election. Weekly average polling results are used as proxy for "games". After each weekly poll, the candidate gains or lose elo based on whether they win or lose (polling average \> 50%) and how much did they win (or lose) by. Some **major caveats and assumptions:**

-   First, this model is for fun, and does not consider variables such as demographics, economics, recent news, etc., which are considered part of the fundamentals portion of any reliable forecasting model. Since the model ingests polling averages from FiveThirtyEight, it does account for quality of polling and other associated factors as a proxy.

-   Second, the model does not account for random effects occuring at the state level or across time, as each unit of polling is considered to be independent.

-   Third, the model rewards consistent polling, and rewards them with higher probability of winning. I would say this is a reasonable assumption as performance in the polls with high margins often indicate a victory in that jurisdcition. However, as many consumers of election modelling know, factors such as close to election day scandals or turnout would affect the final results and violate this assumption.

## Methods   

### "Training" data  
Let's start our modeling exercise by reading in basic polling data from FiveThirtyEight:

```{r pollingdat, echo=TRUE, message = F}
data <- read.csv(file = "data/presidential_poll_averages_2020.csv")
proc_data <- data %>% as_tibble() %>% mutate(modeldate = as_date(strptime(modeldate, format = "%m/%d/%Y"))) %>% # reformat names
  mutate(candidate_name = case_when(
    candidate_name == "Convention Bounce for Joseph R. Biden Jr." ~ "Joseph R. Biden Jr.",
    candidate_name == "Convention Bounce for Donald Trump" ~ "Donald Trump", 
    TRUE ~ candidate_name
  )) %>% mutate(week = week(modeldate)) %>% filter(!state %in% c("NE-1", "NE-2", "ME-1", "ME-2", "National")) %>% # for simplicity
  group_by(state, week, candidate_name) %>% # get week 
  summarise(poll_avg = mean(pct_trend_adjusted)) # average per week 
```

```{r}
rmarkdown::paged_table(proc_data)
```

### Prior information for initial elo seeding  

We seeded initial elo based on election results from the 2016 election. using 1000 elo as a baseline, we subtract or add points to candidate's starting elo based on how they (or the candidate belonging to their party) performed previously. We call this our priors.   

```{r priordat, echo=TRUE, message = FALSE}
# Function to convert abbreviation to state name
get_stname <- function(state_abb){
  if (state_abb == "DC"){
    return("District of Columbia")
  } else {
    return(state.name[grep(state_abb, state.abb)])
  }
}
# Prior information 
prior <- read.csv(file = "data/returns-2016.csv") %>% as_tibble()

# convert state abbreviation to name, renormalize to two party candidates, then back transform prob to difference in elo
prior <- prior %>% mutate(state = map_chr(state_abbreviation, ~get_stname(.x))) %>% 
  mutate(Clinton = Clinton/(Clinton + Trump), Trump = Trump/(Clinton + Trump)) %>% 
  select(-c(state_abbreviation, Other)) %>% 
  mutate(elo_diff = back_transformation(abs(Clinton - Trump)))
```

```{r}
rmarkdown::paged_table(prior)
```

### Incorporating margin of victory  

We incorporate margin of victory into our elo update calculation by modifying the K-factor. This is a simple linear adjustment $$K_{eff} = K * mov$$ where $$mov$$ is the margin of victory. This means that the "winning" candidate will gain points as a proportion of K that is equal to their margin of polling victory. As such, we increase values of K significantly to compensate for the low gains in elo when margins can be 1 percent.  

```{r, echo=TRUE}
# Update elo using those rankings  

update_elo <- function(r1, r2, outcome, mov, K=30){
  probs <- win_prob(r1, r2)
  p1 <- probs$p1
  p2 <- probs$p2
  K = K * mov # K-gains as a proportion of margin of victory  
  r1_new <- round(r1 + K*(outcome - p1), digits = 0)
  r2_new <- round(r2 + K*((1 - outcome) - p2), digits = 0)
  return(list(r1 = r1_new, r2 = r2_new))
}
```

### Getting elo sequence  
Let's get elo sequence for each state, given prior information from the 2016 election and weekly average polls with the Democratic candidate as the focal candidate with rankings equals $r1$. First, let's define a function that wraps this procedure up for each state. This function takes the working data and the prior data, and returns an elo sequence from the initial week (defined as the first week prior to the first available polling week by state) to the last available week.  

```{r, echo=TRUE, waring=FALSE}
get_sequence <- function(proc_data, prior, st, init=1000, K = 50){
  df <- proc_data %>% filter(state == st) # filter by state
  weeks <- unique(df$week) # get all unique weeks 
  elo <- vector(mode = "list", length = length(weeks) + 1) # initialize elo vector
  prior_diff <- prior %>% filter(state == st) %>% pull(elo_diff)
  elo[[1]] <- tibble(
    DT_elo = init - prior_diff,
    JB_elo = init + prior_diff
  )
  # iterate 
  for (i in 2:length(elo)){
    elos <- update_elo(r1 = elo[[i-1]]$JB_elo, 
                       r2 = elo[[i-1]]$DT_elo,
                       outcome = df$win[i-1], 
                       mov = df$mov[i-1], K = K)
    elo[[i]] <- tibble(
      DT_elo = elos$r2,
      JB_elo = elos$r1,
    )
  }
  seq <- do.call(rbind, elo)
  weeks <- c(min(weeks)-1, weeks)
  seq <- seq %>% mutate(state = rep(st, length(elo)), week = weeks)
  seq <- seq %>% select(state, week, DT_elo, JB_elo) %>% 
    pivot_longer(c(DT_elo, JB_elo), names_to = "candidate", values_to = "elo") %>% 
    mutate(candidate = recode(candidate, DT_elo = "DT", JB_elo = "JB")) %>% 
    pivot_wider(names_from = candidate, values_from = elo)
  return(seq)
}
```

Let's apply this for all states to our data:  

```{r, echo=TRUE, warning=FALSE}
proc_data <- proc_data %>% mutate(candidate_name = case_when(candidate_name == "Donald Trump" ~ "DT", TRUE ~ "JB")) %>% 
  pivot_wider(names_from = "candidate_name", values_from = "poll_avg") %>% 
  mutate(win = case_when(JB > DT ~ as.integer(1), 
                         JB < DT ~ as.integer(0), 
                         JB == DT ~ rbinom(1,1,0.5))) %>% 
  mutate(mov = abs(DT - JB)/100)


get_elo_all_states <- function(proc_dat, prior, K=50, init=1000){
  states <- unique(proc_data$state)
  data <- vector(mode = "list", length = length(states))
  for (i in seq_len(length(states))){
    data[[i]] <- get_sequence(proc_data, prior, states[i], K = K, init = init)
  }
  return(do.call(dplyr::bind_rows, data))
}

elo_sequences <- get_elo_all_states(proc_dat, prior)
elo_sequences <- elo_sequences %>% rowwise() %>% mutate(prob = win_prob(r1 = JB, r2 = DT)$p1)
```  

```{r}
rmarkdown::paged_table(elo_sequences)
```


### Final probabilities using Monte Carlo simulations   
Finally, we perform elo modeling at the state level, then use those probabilities to randomly draw a number of simulations based on a Bernoulli process. We calculate the final probability of winning as the number of simulations where a focal candidate (in this case Biden) gains 270 or more Electoral Votes.  

Let's create a function that wraps all of this together in one go:  

```{r, echo=TRUE}
elo_predict <- function(proc_data, prior, K = 50, init = 1000, n_iter = 1000){
  elo_sequences <- get_elo_all_states(proc_dat = proc_dat, prior = prior, K = K, init = init)
  probs <- elo_sequences %>% group_by(state) %>% summarise(prob = prob[which.max(week)])
  return(0)
  #probs %>% mutate(predicts = list(rbinom(1000, size = 1, prob = 0.5))) %>% unnest(predicts)
}
```

## Results  
